
# coding: utf-8

# # 概要

# トレーニングデータセットの特徴量に基づいて一連の質問を学習し、サンプルのクラスラベルを推測する<br>
# 決定木の目的関数はシタキのように定義されている。<br>
# $IG(D_p,f)=I(D_p)-\sum^{m}_{j=1}\frac{N_j}{N_p}I(D_j)$<br>
#   ・$fは分割の特徴量$<br>
#   ・$D_pは親のデータセット、D_jはj番目の子ノードのデータセット$<br>
#   ・$Iは負純度$<br>
#   ・$N_pは親ノードのサンプルの総数、N_jはj番目の子ノードのサンプルの総数$<br>
# 過学習を防ぐため、決定着の深さに制限を付ける

# In[1]:

from IPython.display import Image
Image(filename='./images/03_15.png', width=500) 


# ## 負純度

# 2分木決定機でよく使用される負純度は下のとおり<br>
# ・$ジニ負純度（I_G）$<br>
# ・$エントロピー（I_H）$<br>
# ・$分類誤差(I_E)$<br>
# 

# In[ ]:



